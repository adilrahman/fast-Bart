# fast-Bart
Convert Huggingface's BART models to Onnx with quantization. 

**4X reduction in size, and upto 3X reduction is compute time.**
